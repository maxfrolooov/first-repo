n <- 83
set.seed(1542643545) # случайные числа, псевдослучайные

eps <- rnorm(n) # mean = 0, sd = 1
#qnorm()
#pnorm()
mean(eps)
var(eps)

x <- rnorm(n, mean=3, sd=2)

y <- -5 + 2 * x + eps

plot(y ~ x) # диаграмма

rug(x, side=3) # бахрома
rug(y, side=4)

grid() # сетка

# корреляция, paste0 - склеить без пробела, round округление
s_cor <- round(cor(x, y),4)
text(4, -4, paste0("r=", s_cor)) # текстовая надпись на диаграмме

plot(data.frame(y,x,eps)) # попарные графики

abline(v=mean(x), h = mean(y))

# matrix(c(1, 4/sqrt(17), 1/sqrt(17)), ncol=3)
cor_matrix <- cor(matrix(c(y, x, eps), ncol=3)) # корреляционная матрица для выборки + ниже ковариационная
cov_matrix <- cov(matrix(c(y, x, eps), ncol=3))
# matrix(cbind(y,x,eps), ncol = 3)

cov.yeps <- matrix(c(17, 8, 1, 8, 4, 0, 1, 0, 1), nrow=3) # теоритическая ковариационная матрица
sd.yxeps <- sqrt(diag(cov.yeps)) # стандартное отклонение
#corr.yxeps <- t(1/sd.yxeps)
corr.yxeps <- matrix(rep(NA, 9), ncol=3) 

for (i in 1:nrow(cov.eps)){
  for (j in 1:nrow(cov.eps)){
    corr.yxeps[i,j] <- round(cov.eps[i,j] / sd.yxeps[i] / sd.yxeps[j], 3)
  }
}
corr.yxeps
cor_matrix

cov.eps
cov_matrix

# Проведите тест, что y имеет нулевое математическое ожидание (команда t.test).

plot(y) # смотрим графически, среднее выше нуля
abline(h=0, col = "red")
abline(h=mean(y), col = "green")
t.test(y) # нулевую гипотезу отвергаем, среднее сстатитистически значимо больше 0

# Проведите тест, что x и y некоррелированы (команда cor.test для пары векторов).

cor.test(y,x) # коэффициент корреляции значимо отличается от 0, нулевую гипотезу отвергаем. Очень сильная корреляция, p значени 10^-16

# Проведите тест, что x и y имеют одинаковое математическое ожидание в предположении, что дисперсии разные для парных и 
#непарных наблюдений (команда t.test для пары векторов, опции var.equal = FALSE – по умолчанию,  paired = FALSE или TRUE).

t.test(y, x, var.equal = FALSE) # мат ожидания статистически отличаются друг от друга для непарных наблюдений
t.test(y, x, var.equal = FALSE, paired = TRUE) # мат ожидания статистически отличаются друг от друга для парных наблюдений

# Проведите неформальную проверку на нормальность  переменной y с помощью коэффициента асимметрии, коэффициента куртозиса, 
# гистограммы с нормальной кривой, нормальной QQ-диаграммы (команды qqnorm и qqline).

t.test(scale(y)^3) # ассиметрия статистически не отличается от 0, нулевую гипотезу принимаем
t.test(scale(y)^4-3) # куртозис статистически не отличается от 0, нулевую гипотезу принимаем
qqnorm(scale(y)) # графически квантиль распределения данных y лежит на линии нормальной кривой, имеются незначительные выбросы на концах
qqline(scale(y))

shapiro.test(y) # p - value = 0,76 > 0.05, распределение на уровне значимости 0.05 имеет нормальное распределение

hist(y, breaks = 10, freq = FALSE)
curve(dnorm(x, mean(y), sd(y)), add = TRUE, col = "blue")
