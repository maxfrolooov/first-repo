df <- df[(n:1), ]
df <- df[(nrow(df):1), ]
View(df)
View(df)
df1 <- df$Date > "1998-01-01"
df1 <- df[df$Date > "1998-01-01"]
View(df)
df1 <- df[df$Date > "1998-01-01"]
View(df)
View(df)
df$Date == "1998-01-01"
df$Date > "1998-01-01"
df$Date > "1951-01-01"
df$Date > "1951"
df1 <- df[df$Date > "1998"]
df1 <- df[df$Date > 1951]
df1 <- df[df$Date > "1951"]
df1 <- df[df$Date > "1998"]
df1 <- df[df$Date > "1991"]
df$Date > "1951"
df <- read.csv("US_sp500.csv", stringsAsFactors=FALSE)
df <- df[(nrow(df):1), ]
df1 <- df[df$Date > "1991"]
df$Date > "1951"
df1 <- df[df$Date > "1991"]
df$Date > "1951"
df1 <- df[df$Date > "1991-01-01"]
df1 <- df[df$Date > "1991-01-01"]
df1 <- df[df$Date > "1998-01-01"]
df$Date > "1951-01-01"
df1 <- df[df$Date > "1998-01-01", ]
df1 <- df1[df1$Date < "2003-01-01", ]
View(df1)
df1 <- df[df$Date >= "1998-01-01", ]
df1 <- df1[df1$Date < "2003-01-01", ]
View(df1)
View(df1)
r <- diff(log(df1$Close)) * 100 # логарифмические доходности
plot.ts(r)
abline(h=0, col="blue")
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
var(r)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Оценка волатильости !!!!!
df2 <- read.csv("US_sp500.csv", stringsAsFactors = FALSE)
r <- diff(log(df2$Close)) * 100 # логарифмические доходности
plot.ts(r)
abline(h=0, col="blue")
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.csv("US_sp500.csv", stringsAsFactors=FALSE)
df <- df[(nrow(df):1), ]
df1 <- df[df$Date >= "1998-01-01", ]
df1 <- df1[df1$Date < "2003-01-01", ]
r <- diff(log(df1$Close)) * 100 # логарифмические доходности
plot.ts(r)
abline(h=0, col="blue")
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
var(r)
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
var(r)
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
var(r)
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
var(r)
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # имеется кластеризация волатильности, акф для доходности выше дов. интервала для белого шума
var(r)
# Riskmetrics
a <- 0.05
var(r)
# Riskmetrics
a <- 0.05
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol <- sqrt(s2) # волатильность
plot.ts(vol) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
a <- 0.1
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
lines(vol2, col="red", lwd=2)
plot.ts(r)
lines(vol, col="red", lwd=2)
lines(vol2, col="blue", lwd=2)
# 3Б) Riskmetrics
a <- 0.05
s1 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s1[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol <- sqrt(s1) # волатильность
plot.ts(vol) # в процентных пунктах
a <- 0.1
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
lines(vol2, col="blue", lwd=2)
for (t in 1:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
# 3в)
L1 <- (r[1]^2)/(s1[1]) + log(s1[1])
for (t in 2:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
mean(L1)
L2 <- (r[1]^2)/(s2[1]) + log(s2[1])
for (t in 2:TT)
L2[t] <- (r[t]^2)/(s2[t]) + log(s2[t])
mean(L2)
mean(L2)
mean(L1)
mean(L2)
mean(L1)
a <- 0.2
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
lines(vol2, col="blue", lwd=2)
# 3в)
L1 <- (r[1]^2)/(s1[1]) + log(s1[1])
for (t in 2:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
L2 <- (r[1]^2)/(s2[1]) + log(s2[1])
for (t in 2:TT)
L2[t] <- (r[t]^2)/(s2[t]) + log(s2[t])
mean(L2)
mean(L1)
a <- 0.3
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
lines(vol2, col="blue", lwd=2)
# 3в)
L1 <- (r[1]^2)/(s1[1]) + log(s1[1])
for (t in 2:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
L2 <- (r[1]^2)/(s2[1]) + log(s2[1])
for (t in 2:TT)
L2[t] <- (r[t]^2)/(s2[t]) + log(s2[t])
mean(L2)
mean(L1)
library(lmtest)
library(sandwich)
reg11 <- lm(L2 - L1 ~ 1) # строим регрессию от const
lmtest::coeftest(reg11, vcov=vcovHAC)
reg11 <- lm(L1 - L2 ~ 1) # строим регрессию от const
lmtest::coeftest(reg11, vcov=vcovHAC)
reg11 <- lm(L2 - L1 ~ 1) # строим регрессию от const
lmtest::coeftest(reg11, vcov=vcovHAC)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# a)
df <- read.csv("1_13.csv", stringsAsFactors=FALSE)
lgt=glm(df$y~df$x1+df$x2, family = "binomial")
summary(lgt)
# a)
df <- read.csv("1_13.csv", stringsAsFactors=FALSE)
lgt=glm(df$y~df$x1+df$x2, family = "binomial")
summary(lgt)
fitted(lgt) # расчетные
predict.glm(lgt) # предсказанные
plot(df$y ~ predict.glm(lgt), col = 'blue')
points(fitted(lgt) ~ predict.glm(lgt), pch = '--')
pROC::plot.roc(df$y, fitted(lgt))
# б)
df2 <- df[, c("x1", "x2")]
km <- kmeans(df2, 4, nstart=50)
plot(x2~x1, data=df2, col=km$cluster+1, pch=16+km$cluster) # наблюдается ровная граница
plot(x2~x1, data=df2, col=km$cluster+1, pch=16+km$cluster) # наблюдается ровная граница
points(km$centers, pch=3, cex=3, lwd=3)
text(km$centers[,1], km$centers[,2], 1:4, cex=3, pos=4)
df$z <- factor(km$cluster)
lgt2=glm(df$y~df$x1+df$x2+df$z, family = "binomial")
summary(lgt2)
fitted(lgt2) # расчетные
predict.glm(lgt2) # предсказанные
plot(df$y ~ predict.glm(lgt2), col = 'blue')
points(fitted(lgt2) ~ predict.glm(lgt2), pch = '--')
pROC::plot.roc(df$y, fitted(lgt))
par(new=TRUE)
pROC::plot.roc(df$y, fitted(lgt2), col="blue")
summary(lgt2)
# д)
table(df$y, fitted(lgt2) > 0.5)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(readxl)
df <- read_excel("task2.xlsx", skip = 0)
# 1)
plot.ts(df$GAZ_C)
y <- log(df$GAZ_C)
acf(y, lag.max=50)
plot.ts(y)
h <- 24 # делаем прогноз на 2 года последних
TT <- length(y) - h
sarma <- arima(y[1:TT], order=c(1,1,1),  # period - сколько сезонов. сезонность у нас не меняется - стационарная
seasonal = list(order = c(1, 0, 1), period=12)) # order (p, d, q)- порядок arima, d - сколько разностей взять для стационарности
sarma
plot(residuals(sarma)) # белый щум, который мы оценили - остатки
yp <- predict(sarma, n.ahead=h)$pred # строим прогноз, h - горизонт прогноза. первая часть - точечный прогноз, вторая - сигма е.
sp <- predict(sarma, n.ahead=h)$se
plot.ts(y[(TT+1):(TT+h)])
points(y[(TT+1):(TT+h)])
lines(c(yp), col="blue")
L <- yp - qnorm(1-0.05/2)*sp # lower, 95 % интервал
U <- yp + qnorm(1-0.05/2)*sp # upper
lines(c(L), col="red") # у arima интервал расширяется, у arma нет, он стабилизируется.
lines(c(U), col="green")
epep <- y[(TT+1):(TT+h)] - yp # вычисляем ошибки
ts.plot(epep) # график ошибок
abline(h=0, col="blue")
# MSE
MSE <- mean(epep^2)
RMSE <- sqrt(MSE)
RMSE
MAE <- mean(abs(epep))
MAE
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# 3a)
df <- read.csv("US_sp500.csv", stringsAsFactors=FALSE)
df <- df[(nrow(df):1), ]
df1 <- df[df$Date >= "1998-01-01", ]
df1 <- df1[df1$Date < "2003-01-01", ]
r <- diff(log(df1$Close)) * 100 # логарифмические доходности
plot.ts(r)
abline(h=0, col="blue")
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # имеется кластеризация волатильности, акф для доходности выше дов. интервала для белого шума
var(r)
# 3Б) Riskmetrics
a <- 0.05
s1 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s1[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol <- sqrt(s1) # волатильность
plot.ts(vol) # в процентных пунктах
plot.ts(vol) # в процентных пунктах
# 3Б) Riskmetrics
a <- 0.05
s1 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s1[t] <- a * r[t-1]^2 + (1-a)*s1[t-1]
vol <- sqrt(s1) # волатильность
plot.ts(vol) # в процентных пунктах
a <- 0.3
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
lines(vol2, col="blue", lwd=2)
# 3в)
L1 <- (r[1]^2)/(s1[1]) + log(s1[1])
for (t in 2:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
L2 <- (r[1]^2)/(s2[1]) + log(s2[1])
for (t in 2:TT)
L2[t] <- (r[t]^2)/(s2[t]) + log(s2[t])
mean(L2)
mean(L1)
library(lmtest)
library(sandwich)
reg11 <- lm(L2 - L1 ~ 1) # строим регрессию от const
lmtest::coeftest(reg11, vcov=vcovHAC)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# a)
df <- read.csv("1_13.csv", stringsAsFactors=FALSE)
lgt=glm(df$y~df$x1+df$x2, family = "binomial")
# a)
df <- read.csv("1_13.csv", stringsAsFactors=FALSE)
lgt=glm(df$y~df$x1+df$x2, family = "binomial") # стромм логит регрессию от x1 и x2
summary(lgt) # параметры регрессии
fitted(lgt) # расчетные
predict.glm(lgt) # предсказанные
plot(df$y ~ predict.glm(lgt), col = 'blue')
points(fitted(lgt) ~ predict.glm(lgt), pch = '--')
# б)
df2 <- df[, c("x1", "x2")]
km <- kmeans(df2, 4, nstart=50)
plot(x2~x1, data=df2, col=km$cluster+1, pch=16+km$cluster) # наблюдается ровная граница
points(km$centers, pch=3, cex=3, lwd=3)
text(km$centers[,1], km$centers[,2], 1:4, cex=3, pos=4)
df$z <- factor(km$cluster)
lgt2=glm(df$y~df$x1+df$x2+df$z, family = "binomial")
summary(lgt2)
fitted(lgt2) # расчетные
summary(lgt2)
fitted(lgt2) # расчетные
predict.glm(lgt2) # предсказанные
plot(df$y ~ predict.glm(lgt2), col = 'blue')
points(fitted(lgt2) ~ predict.glm(lgt2), pch = '--')
pROC::plot.roc(df$y, fitted(lgt))
par(new=TRUE)
pROC::plot.roc(df$y, fitted(lgt2), col="blue")
summary(lgt2)
# д)
table(df$y, fitted(lgt2) > 0.5)
summary(lgt) # параметры регрессии
fitted(lgt) # расчетные
predict.glm(lgt) # предсказанные
# График наблюдений с вероятностями
plot(df$y ~ predict.glm(lgt), col = 'blue')
points(fitted(lgt) ~ predict.glm(lgt), pch = '--')
pROC::plot.roc(df$y, fitted(lgt)) # ROC кривая для имеющихся данных, не прогнозов
# График наблюдений с вероятностями
plot(df$y ~ predict.glm(lgt), col = 'blue')
points(fitted(lgt) ~ predict.glm(lgt), pch = '--')
# б)
df2 <- df[, c("x1", "x2")]
km <- kmeans(df2, 4, nstart=50)
# б)
df2 <- df[, c("x1", "x2")]
km <- kmeans(df2, 4, nstart=50)
# б)
df2 <- df[, c("x1", "x2")]
km <- kmeans(df2, 4, nstart=50)
plot(x2~x1, data=df2, col=km$cluster+1, pch=16+km$cluster) # 4 кластера, наблюдаем ровную границу между областями
points(km$centers, pch=3, cex=3, lwd=3)
text(km$centers[,1], km$centers[,2], 1:4, cex=3, pos=4)
lgt2=glm(df$y~df$x1+df$x2+df$z, family = "binomial") # старая модель + переменная z добавим
summary(lgt2)
fitted(lgt2) # расчетные
predict.glm(lgt2) # предсказанные
plot(df$y ~ predict.glm(lgt2), col = 'blue')
points(fitted(lgt2) ~ predict.glm(lgt2), pch = '--')
lgt=glm(df$y~df$x1+df$x2, family = "binomial") # стромм логит регрессию от x1 и x2
summary(lgt) # параметры регрессии
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# a)
df <- read.csv("1_13.csv", stringsAsFactors=FALSE)
lgt=glm(df$y~df$x1+df$x2, family = "binomial") # стромм логит регрессию от x1 и x2
summary(lgt) # параметры регрессии
pROC::plot.roc(df$y, fitted(lgt))
par(new=TRUE)
pROC::plot.roc(df$y, fitted(lgt2), col="blue") # ROC кривая для 2 модели лучше, визуально площадь значительно больше, прогноз точнее
lgt2=glm(df$y~df$x1+df$x2+df$z, family = "binomial") # старая модель + переменная z добавим
summary(lgt2)
summary(lgt2)
summary(lgt2)
# д)
table(df$y, fitted(lgt2) > 0.5)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(readxl)
df <- read_excel("task2.xlsx", skip = 0)
# 1)
plot.ts(df$GAZ_C)
y <- log(df$GAZ_C)
y <- log(df$GAZ_C) # взяли сезонные данные и пролагорифмировали
acf(y, lag.max=50)
yp <- predict(sarma, n.ahead=h)$pred # строим прогноз, h - горизонт прогноза. первая часть - точечный прогноз, вторая - сигма е.
sp <- predict(sarma, n.ahead=h)$se
plot.ts(y[(TT+1):(TT+h)])
points(y[(TT+1):(TT+h)])
# MSE
MSE <- mean(epep^2)
RMSE <- sqrt(MSE)
# MSE
MSE <- mean(epep^2)
RMSE <- sqrt(MSE)
RMSE
MAE <- mean(abs(epep))
MAE
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df1 <- read.delim("USA_Icecream.tsv", skip=21, sep="", stringsAsFactors = FALSE)
df2 <- read.delim("DEU_Dairy.tsv", skip=16, sep="")
# второе задание, ложная корреляция при сезонности
cor.test(df1$VALUE, df2$dairy) # cor = 0.49031, p-value = 10^-16. Значимо отличается от 0.
# Прогнозирование с помощью тренда и сезонных фиктивных переменных
x <- df1$VALUE
train <- df1$DATE < "1939-01-01"
plot.ts(x)
#прогноз на последние 24 месяца по модели с линейным трендом и месячными фиктивными переменными.
tr <- 1:nrow(df1)
month <- rep(1:12, 23) # 12 месяцев, 23 года период
plot.ts(x[train])
lines(fitted(reg1), col="blue")
xp <- predict(reg1, newdata=list(tr=tr[test], month=month[test])) # получаем прогноз
plot.ts(x[test])
lines(xp, col="blue", lw=2) # график прогноза
epep <- x[test] - xp # вычисляем ошибки
test <- ! train # Тестовый период последние 24 месяца
abline(h=0, col="blue")
# MSE
MSE <- mean(epep^2)
RMSE
RMSE <- sqrt(MSE)
reg1 <- lm(x ~ tr + factor(month), subset=train) # регрессия на train периоде
ts.plot(epep) # график ошибок
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# 3a)
df <- read.csv("US_sp500.csv", stringsAsFactors=FALSE)
df <- df[(nrow(df):1), ]
df1 <- df[df$Date >= "1998-01-01", ]
df1 <- df1[df1$Date < "2003-01-01", ]
r <- diff(log(df1$Close)) * 100 # логарифмические доходности
plot.ts(r)
abline(h=0, col="blue")
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # имеется кластеризация волатильности, акф для доходности выше дов. интервала для белого шума
var(r)
acf(r^2) # АКФ, синий - дов. интервал для белого шума
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# 3a)
df <- read.csv("US_sp500.csv", stringsAsFactors=FALSE)
df <- df[(nrow(df):1), ]
df1 <- df[df$Date >= "1998-01-01", ]
df1 <- df1[df1$Date < "2003-01-01", ]
r <- diff(log(df1$Close)) * 100 # логарифмические доходности
plot.ts(r)
abline(h=0, col="blue")
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # имеется кластеризация волатильности, акф для доходности выше дов. интервала для белого шума
var(r)
# 3Б) Riskmetrics
a <- 0.05
# 3Б) Riskmetrics
a <- 0.05
s1 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s1[t] <- a * r[t-1]^2 + (1-a)*s1[t-1]
vol <- sqrt(s1) # волатильность
plot.ts(vol) # в процентных пунктах
a <- 0.3
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
# 3Б) Riskmetrics
a <- 0.05
s1 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s1[t] <- a * r[t-1]^2 + (1-a)*s1[t-1]
vol <- sqrt(s1) # волатильность
plot.ts(vol) # в процентных пунктах
a <- 0.3
s2 <- var(r) # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol2 <- sqrt(s2) # волатильность
plot.ts(vol2) # в процентных пунктах
# 3в)
L1 <- (r[1]^2)/(s1[1]) + log(s1[1])
for (t in 2:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
L2 <- (r[1]^2)/(s2[1]) + log(s2[1])
for (t in 2:TT)
L2[t] <- (r[t]^2)/(s2[t]) + log(s2[t])
# 3в)
L1 <- (r[1]^2)/(s1[1]) + log(s1[1])
for (t in 2:TT)
L1[t] <- (r[t]^2)/(s1[t]) + log(s1[t])
L2 <- (r[1]^2)/(s2[1]) + log(s2[1])
for (t in 2:TT)
L2[t] <- (r[t]^2)/(s2[t]) + log(s2[t])
mean(L2)
mean(L1)
mean(L2)
mean(L1)
library(lmtest)
library(sandwich)
library(lmtest)
library(sandwich)
reg11 <- lm(L2 - L1 ~ 1) # строим регрессию от const
lmtest::coeftest(reg11, vcov=vcovHAC)
