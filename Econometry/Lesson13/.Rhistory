plot(resid(reg1))
plot.ts(resid(reg1))
plot.ts(resid(reg1)[1:100])
plot(df$x ~ df$date, type="l")
acf(df$x) # автокорреляционная функция не угасает, медленно убывает. Похоже на нестационарность.
acf(df$x)[1] # первая автокорреляция
plot.ts(resid(reg1)[1:100])
plot.ts(resid(reg1)[1:50])
#plot.ts(resid(reg1)[1:50])
summary(reg1) # коэф. автокорреляции 0.688
# Прогнозирование
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.delim("Exchange_Rate_Report.tsv", skip=0, sep="")
Sys.setlocale("LC_TIME", "C")
df$Date <- as.Date(df$Date, "%d-%b-%Y") # преобразовываем дату
x <- df$Swiss_franc
plot.ts(x)
# Прогнозирование
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.delim("Exchange_Rate_Report.tsv", skip=0, sep="")
# Прогнозирование
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.delim("Exchange_Rate_Report.tsv", skip=0, sep="")
Sys.setlocale("LC_TIME", "C")
df$Date <- as.Date(df$Date, "%d-%b-%Y") # преобразовываем дату
x <- df$Swiss_franc
View(df)
# Прогнозирование
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.delim("Exchange_Rate_Report.tsv", skip=0, sep="")
View(df)
Sys.setlocale("LC_TIME", "C")
df$Date <- as.Date(df$Date, "%d-%b-%Y") # преобразовываем дату
x <- df$Swiss_franc
plot.ts(x)
# 1 задание: Разделить на ряды по 20 наблюдений и создать из них матрицу (matrix(x, nrow=20))
XX <- matrix(x, nrow=20)
View(XX)
XX <- XX[, -24]
# 1 задание: Разделить на ряды по 20 наблюдений и создать из них матрицу (matrix(x, nrow=20))
XX <- matrix(x, nrow=20)
XX <- XX[, -24]
# 1 задание: Разделить на ряды по 20 наблюдений и создать из них матрицу (matrix(x, nrow=20))
XX <- matrix(x, nrow=20)
XX <- XX[, -24]
# 1 задание: Разделить на ряды по 20 наблюдений и создать из них матрицу (matrix(x, nrow=20))
XX <- matrix(x, nrow=20)
View(XX)
# Рассчитать матрицу корреляций.
RR <- cor(XX)
View(RR)
# 1 задание: Разделить на ряды по 20 наблюдений и создать из них матрицу (matrix(x, nrow=20))
XX <- matrix(x, nrow=20)
XX <- XX[, -24]
# Рассчитать матрицу корреляций.
RR <- cor(XX)
rr <- c(RR[lower.tri(RR)]) # нижний треугольник
hist(rr) # получили много ложных корреляций и на гистограмме это хорошо видно
# Задание 2. Многошаговое прогнозирование валютного курса с помощью тренда
train <- df$Date < "2020-01-03" # На тех же данных. Тренировочный период 1 год – построить линейный тренд. Нарисовать.
test <- ! train
tr <- 1:nrow(df)
View(df)
View(df)
View(df)
reg1 <- lm(x ~ tr, subset=train) # линейная регрессия на первом году
plot.ts(x[train])
lines(fitted(reg1), col="blue") # расчетное значение
xp <- predict(reg1, newdata=list(tr=tr[test])) # получаем прогноз
plot.ts(x[test])
lines(xp, col="blue", lw=2)
tr2 <- tr^2 # сделаем для квадратичного тренда
reg2 <- lm(x ~ tr+tr2, subset=train) # линейная регрессия на первом году
plot.ts(x[train])
lines(fitted(reg2), col="blue")
xp2 <- predict(reg2, newdata=list(tr=tr[test], tr2=tr2[test])) # получаем прогноз
plot.ts(x[test])
lines(xp2, col="blue", lw=2)
# Задание 3.
x1 <- c(x[1], x[-length(x)]) #первый лаг
x2 <- c(x1[1], x1[-length(x)])
AR1 <- lm(x ~ x1, subset=train)
cfAR1 <- coef(AR1)
AR2 <- lm(x ~ x1+x2, subset=train)
cfAR2 <- coef(AR2)
AR02 <- lm(x ~ x2, subset=train)
cfAR02 <- coef(AR02)
xpRW <- x1[test]
xpAR1 <- cfAR1[1] + cfAR1[2] * x1[test]
xpAR2 <- cfAR2[1] + cfAR2[2] * x1[test] + cfAR2[3] * x2[test]
xpAR02 <- cfAR02[1] + cfAR02[2] * x2[test]
xpxp <- cbind(xpRW, xpAR1, xpAR2, xpAR02) # прогнозные значения
ts.plot(xpxp, col=1:4)
# ошибки прогноза
epep <- x[test] - xpxp
ts.plot(epep, col=1:4)
abline(h=0)
MSE <- colMeans(epep^2) # среднее по столбцам. Получаем средний квадрат ошибки
RMSE <- sqrt(MSE)
RMSE
# Значимость, 1 задание
epep[,1]
View(epep)
library(lmtest)
library(sandwich)
reg11 <- lm(epep[,4]^2 - epep[,1]^2 ~ 1)
lmtest::coeftest(reg11, vcov=vcovHAC) # прогноз на основе предыдующего значения значим лучше, чем прогноз со 2 лагом. p-value 10^-10
reg11 <- lm(epep[,4]^2 - epep[,1]^2 ~ 1) # строим регрессию от const
lmtest::coeftest(reg11, vcov=vcovHAC) # прогноз на основе предыдующего значения значим лучше, чем прогноз со 2 лагом. p-value 10^-10
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df1 <- read.delim("USA_Icecream.tsv", skip=21, sep="", stringsAsFactors = FALSE)
df2 <- read.delim("DEU_Dairy.tsv", skip=16, sep="")
# второе задание, ложная корреляция при сезонности
cor.test(df1$VALUE, df2$dairy) # cor = 0.49031, p-value = 10^-16. Значимо отличается от 0.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df1 <- read.delim("USA_Icecream.tsv", skip=21, sep="", stringsAsFactors = FALSE)
df2 <- read.delim("DEU_Dairy.tsv", skip=16, sep="")
# второе задание, ложная корреляция при сезонности
cor.test(df1$VALUE, df2$dairy) # cor = 0.49031, p-value = 10^-16. Значимо отличается от 0.
# Прогнозирование с помощью тренда и сезонных фиктивных переменных
x <- df1$VALUE
plot.ts(x)
train <- df1$DATE < "1939-01-01"
test <- ! train # Тестовый период последние 24 месяца
#прогноз на последние 24 месяца по модели с линейным трендом и месячными фиктивными переменными.
tr <- 1:nrow(df1)
month <- rep(1:12, 23) # 12 месяцев, 23 года период
#прогноз на последние 24 месяца по модели с линейным трендом и месячными фиктивными переменными.
tr <- 1:nrow(df1)
month <- rep(1:12, 23) # 12 месяцев, 23 года период
reg1 <- lm(x ~ tr + factor(month), subset=train) # регрессия на train периоде
plot.ts(x[train])
lines(fitted(reg1), col="blue")
xp <- predict(reg1, newdata=list(tr=tr[test], month=month[test])) # получаем прогноз
plot.ts(x[test])
lines(xp, col="blue", lw=2) # график прогноза
epep <- x[test] - xp # вычисляем ошибки
ts.plot(epep) # график ошибок
abline(h=0, col="blue")
epep <- x[test] - xp # вычисляем ошибки
ts.plot(epep) # график ошибок
plot.ts(x[test])
lines(xp, col="blue", lw=2) # график прогноза
epep <- x[test] - xp # вычисляем ошибки
ts.plot(epep) # график ошибок
abline(h=0, col="blue")
#прогноз на последние 24 месяца по модели с линейным трендом и месячными фиктивными переменными.
tr <- 1:nrow(df1)
month <- rep(1:12, 23) # 12 месяцев, 23 года период
reg1 <- lm(x ~ tr + factor(month), subset=train) # регрессия на train периоде
plot.ts(x[train])
lines(fitted(reg1), col="blue")
xp <- predict(reg1, newdata=list(tr=tr[test], month=month[test])) # получаем прогноз
plot.ts(x[test])
lines(xp, col="blue", lw=2) # график прогноза
epep <- x[test] - xp # вычисляем ошибки
ts.plot(epep) # график ошибок
abline(h=0, col="blue")
# MSE
MSE <- mean(epep^2)
RMSE <- sqrt(MSE)
RMSE
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df1 <- read.delim("USA_Icecream.tsv", skip=21, sep="", stringsAsFactors = FALSE)
y <- log(df1$VALUE)
plot.ts(y)
h <- 24 # делаем прогноз на 2 года последних
View(df1)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df1 <- read.delim("USA_Icecream.tsv", skip=21, sep="", stringsAsFactors = FALSE)
df2 <- read.delim("DEU_Dairy.tsv", skip=16, sep="")
# второе задание, ложная корреляция при сезонности
cor.test(df1$VALUE, df2$dairy) # cor = 0.49031, p-value = 10^-16. Значимо отличается от 0.
# Прогнозирование с помощью тренда и сезонных фиктивных переменных
x <- df1$VALUE
plot.ts(x)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df1 <- read.delim("USA_Icecream.tsv", skip=21, sep="", stringsAsFactors = FALSE)
y <- log(df1$VALUE)
plot.ts(y)
h <- 24 # делаем прогноз на 2 года последних
TT <- length(y) - h
sarma <- arima(y[1:TT], order=c(1,1,1),  # period - сколько сезонов. сезонность у нас не меняется - стационарная
seasonal = list(order = c(1, 0, 1), period=12)) # order (p, d, q)- порядок arima, d - сколько разностей взять для стационарности
sarma
plot(residuals(sarma)) # белый щум, который мы оценили - остатки
sarma <- arima(y[1:TT], order=c(1,1,1),  # period - сколько сезонов. сезонность у нас не меняется - стационарная
seasonal = list(order = c(1, 0, 1), period=12)) # order (p, d, q)- порядок arima, d - сколько разностей взять для стационарности
sarma
plot(residuals(sarma)) # белый щум, который мы оценили - остатки
yp <- predict(sarma, n.ahead=h)$pred # строим прогноз, h - горизонт прогноза. первая часть - точечный прогноз, вторая - сигма е.
sp <- predict(sarma, n.ahead=h)$se
yp <- predict(sarma, n.ahead=h)$pred # строим прогноз, h - горизонт прогноза. первая часть - точечный прогноз, вторая - сигма е.
sp <- predict(sarma, n.ahead=h)$se
plot.ts(y[(TT+1):(TT+h)], ylim=c(1, 4))
points(y[(TT+1):(TT+h)], ylim=c(1, 4))
lines(c(yp), col="blue") # точечный прогноз
# интервальный прогноз, предполагаем нормальность
L <- yp - qnorm(1-0.05/2)*sp # lower, 95 % интервал
U <- yp + qnorm(1-0.05/2)*sp # upper
lines(c(L), col="red") # у arima интервал расширяется, у arma нет, он стабилизируется.
lines(c(U), col="green")
# Оценка волатильости !!!!!
df2 <- read.csv("US_sp500.csv", stringsAsFactors = FALSE)
r <- diff(log(df2$Close)) * 100 # логарифмические доходности
plot.ts(r)
View(df2)
abline(h=mean(r), col="red")
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
acf(r^2) # АКФ, синий - дов. интервал для белого шума
acf(abs(r)) # волатильность сильно автокоррелирована
var(r)
# Riskmetrics
a <- 0.05
s2 <- 1 # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol <- sqrt(s2) # волатильность
plot.ts(vol) # в процентных пунктах
plot.ts(vol) # в процентных пунктах
vol <- sqrt(s2) # волатильность
plot.ts(vol) # в процентных пунктах
# Riskmetrics
a <- 0.05
s2 <- 1 # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol <- sqrt(s2) # волатильность
plot.ts(vol) # в процентных пунктах
acf(r^2) # АКФ, синий - дов. интервал для белого шума
abline(h=mean(r), col="red")
plot.ts(r)
# Оценка волатильости !!!!!
df2 <- read.csv("US_sp500.csv", stringsAsFactors = FALSE)
r <- diff(log(df2$Close)) * 100 # логарифмические доходности
plot.ts(r)
# Riskmetrics
a <- 0.05
s2 <- 1 # дисперсия начальная, быстро забывается
vol <- sqrt(s2) # волатильность
# Riskmetrics
a <- 0.05
s2 <- 1 # дисперсия начальная, быстро забывается
TT <- length(r)
for (t in 2:TT)
s2[t] <- a * r[t-1]^2 + (1-a)*s2[t-1]
vol <- sqrt(s2) # волатильность
plot.ts(vol) # в процентных пунктах
plot.ts(r)
plot.ts(vol) # в процентных пунктах
plot.ts(r)
lines(vol, col="red", lwd=2)
# GARCH
library(fGarch)
ga # mu - среднее мю (значимо), shape - параметр распределения (7 степени свободы - толстые хвосты, больше 20 - нормальное почти). skew - скошенность значима
ga <- garchFit(r~ garch(1,1), data.frame(r),
cond.dist="sstd", # условное распределение, sstd - скошенный стьюдент
trace=FALSE)
ga # mu - среднее мю (значимо), shape - параметр распределения (7 степени свободы - толстые хвосты, больше 20 - нормальное почти). skew - скошенность значима
ga # mu - среднее мю (значимо), shape - параметр распределения (7 степени свободы - толстые хвосты, больше 20 - нормальное почти). skew - скошенность значима
ga <- garchFit(r~ garch(1,1), data.frame(r),
cond.dist="sstd", # условное распределение, sstd - скошенный стьюдент
trace=FALSE)
ga # mu - среднее мю (значимо), shape - параметр распределения (7 степени свободы - толстые хвосты, больше 20 - нормальное почти). skew - скошенность значима
plot.ts(r)
lines(volatility(ga), col="blue", lwd=2) # volatility - корень из сигма^2
sarma <- arima(y[1:TT], order=c(1,1,1),  # period - сколько сезонов. сезонность у нас не меняется - стационарная
seasonal = list(order = c(1, 0, 1), period=12)) # order (p, d, q)- порядок arima, d - сколько разностей взять для стационарности
sarma
# ПАНЕЛЬНЫЕ ДАННЫЕ
install.packages("plm") # линейная регрессия для панельных данных
library(plm)
# i - state, t - year.
data("Cigar")
sales <- split(Cigar$sales, Cigar$state) # разбиваем для каждого штата продажи (на душу населения)
View(sales)
View(Cigar)
View(sales)
View(sales)
sales <- split(Cigar$sales, Cigar$state) # разбиваем для каждого штата продажи (на душу населения)
sales <- data.frame(sales)
View(sales)
View(Cigar)
ts.plot(sales, col=1:ncol(sales)) # курить стали меньше
lines(rowMeans(sales), lwd=5)
rowMeans(price)
price <- split(Cigar$price, Cigar$state) # разбиваем для каждого штата цены
sales <- split(Cigar$sales, Cigar$state) # разбиваем для каждого штата продажи (на душу населения)
sales <- data.frame(sales)
ts.plot(sales, col=1:ncol(sales)) # курить стали меньше
lines(rowMeans(sales), lwd=5)
rowMeans(sales)
price <- split(Cigar$price, Cigar$state) # разбиваем для каждого штата цены
price <- data.frame(price)
ts.plot(price, col=1:ncol(sales), log="y") # логарифмируем цены. в 80 видно ускоряющуюся инфляцию
lines(rowMeans(price), lwd=5)
cpi <- Cigar$cpi[Cigar$state == 1] # cpi для всех штатов одинаков
ts.plot(price/cpi, col=1:ncol(sales), log="y") # график реальных цен
View(price)
lines(rowMeans(price/cpi), lwd=5)
# панельный фрейм для регрессии
dfp <- pdata.frame(Cigar, index=c("state", "year"))
class(dfp)
head(index(dfp))
View(dfp)
dfp <- within(dfp, { # чтобы $ не писать каждый раз
lsales <- log(sales)
lrprice <- log(price/cpi)
lp16 <- log(pop16/pop) # pop16 - кол-во старше 16 лет
lrincome <- log(ndi/cpi) # реальный доход
lrpimin <- log(pimin/cpi) # реальная минимальная цена по соседним штатам
})
# создаем лаг продаж для авторегрессии
dfp$lag.lsales <- plm::lag(dfp$lsales)
View(dfp)
# Создаем темпы прироста продаж
dfp$dlsales <- dfp$lsales - dfp$lag.lsales
View(dfp)
dfp <- na.omit(dfp)
View(dfp)
View(dfp)
View(dfp)
View(dfp)
# регрессия обычная
reg.pool.nt <- lm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin, data=dfp) # без времени
summary(reg.pool.nt) # от цены отрицательная зависимость (типо эластичность спроса по цене).
# сквозная регрессия, эффекты штатов отсутствуют
reg.pool <- lm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin + year, data=dfp) # со временем. year берет как качественную переменную
summary(reg.pool)
# с фиксированными эффектами
reg.fe <- lm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin + year + state, data=dfp) # со временем и штатом
summary(reg.fe)
dlsales
View(dfp)
reg.pool.nt <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin,
model="pooling", data=dfp)
summary(reg.pool.nt)
reg.fe <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin,
model="within", effect="twoways", data=dfp) # effect - какой хотим учесть эффект
summary(reg.fe) # plm - все переменные центрированные, зависимая переменная другая. Другой R^2
reg.pool.nt <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin,
model="pooling", data=dfp)
summary(reg.pool.nt)
reg.fe <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin,
model="within", effect="twoways", data=dfp) # effect - какой хотим учесть эффект
summary(reg.fe) # plm - все переменные центрированные, зависимая переменная другая. Другой R^2
# регрессия обычная
reg.pool.nt <- lm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin, data=dfp) # без времени
summary(reg.pool.nt) # от цены отрицательная зависимость (типо эластичность спроса по цене).
reg.pool.nt <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin,
model="pooling", data=dfp)
summary(reg.pool.nt)
reg.fe <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin,
model="within", effect="twoways", data=dfp) # effect - какой хотим учесть эффект
summary(reg.fe) # plm - все переменные центрированные, зависимая переменная другая. Другой R^2
# с фиксированными эффектами
reg.fe <- lm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin + year + state, data=dfp) # со временем и штатом
summary(reg.fe)
# Панельная регрессия со случайными эффектами - продолжение с предыдущего занятия.
reg.re <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin + year,
model="random", data=dfp)
summary(reg.re) # полчили оценки другие по сравнению с фиксированными эффектами
reg.fe <- plm(dlsales ~ lag.lsales + lrprice + lp16 + lrincome + lrpimin + year,
model="random", data=dfp)
phtest(reg.fe, reg.re)
summary(reg.re) # полчили оценки другие по сравнению с фиксированными эффектами
phtest(reg.fe, reg.re)
# 2. Метод k средних (k-means). Сгенерированные данные и квартиры в Октябрьском районе.
n <- 1000
set.seed(123)
df <- data.frame(
grn=sample(1:3, n, replace=TRUE, prob=c(0.5, 0.3, 0.2))) # replace - с возвращением вытягиваем, prob - вероятность что будет группа
df$gr <- c("A", "B", "C")[df$grn]
df$cx <- c(2, 4, 6)[df$grn]# центр для каждой группы. x - переменная
df$cy <- c(6, 2, 4)[df$grn]
df$x <- df$cx + rnorm(n) # генерируем переменные
df$y <- df$cy + rnorm(n)
plot(y~x, data=df, col=df$grn+1, pch=16+df$grn)
View(df)
df <- data.frame(
grn=sample(1:3, n, replace=TRUE, prob=c(0.5, 0.3, 0.2))) # replace - с возвращением вытягиваем, prob - вероятность что будет группа
View(df)
df$gr <- c("A", "B", "C")[df$grn]
View(df)
df$cx <- c(2, 4, 6)[df$grn]# центр для каждой группы. x - переменная
df$cy <- c(6, 2, 4)[df$grn]
rnorm(10)
plot(y~x, data=df, col=df$grn+1, pch=16+df$grn)
df$gr <- c("A", "B", "C")[df$grn]
df$cx <- c(2, 4, 6)[df$grn]# центр для каждой группы. x - переменная
df$cy <- c(6, 2, 4)[df$grn]
df$x <- df$cx + rnorm(n) # генерируем переменные
df$y <- df$cy + rnorm(n)
plot(y~x, data=df, col=df$grn+1, pch=16+df$grn)
points(cy ~ cx, data=df, pch=3, cex=3, lwd=3)
View(df)
text(cy ~ cx, gr, data=df, cex=3, pos=4)
plot(y~x, data=df, pch=16)
df2 <- df[, c("x", "y")]
View(df2)
#plot(y~x, data=df2, pch=16)
km <- kmeans(df2, 3, nstart=50) # 3- центра (кластера), nstart - количество прогонов
str(km) # краткая информация об обьекте
plot(y~x, data=df2, col=km$cluster+1, pch=16+km$cluster) # наблюдается ровная граница
points(km$centers, pch=3, cex=3, lwd=3)
text(km$centers[,1], km$centers[,2], 1:3, cex=3, pos=4)
points(cy ~ cx, data=df, pch=4, cex=3, lwd=3, col="orange")
text(cy ~ cx, gr, data=df, cex=3, pos=2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df <- read.delim("Kvart_Okt.dat", encoding = "UTF-8", header=TRUE, na.strings="-") # квартиры в Октябрьском районе.
names(df) <- c("id", "place", "district", "street", "house.num", "price", "rooms", "area", "liv.area", "kitchen",
"floor", "nfloors")
df <- df[df$liv.area>10,]
df <- df[df$kitchen>1,]
df <- na.omit(df)
summary(df)
plot(price~area, data=df, log="xy")
# Подготовка данных
df2 <- data.frame(
df$rooms,
log(df$price), log(df$area), log(df$liv.area), df$kitchen)
# Подготовка данных
df2 <- data.frame(
df$rooms,
log(df$price), log(df$area), log(df$liv.area), df$kitchen)
df2 <- df2[df2$df.rooms <= 3, ] # убираем 4 комнатные квартиры
df3 <- scale(df2[, -1]) # убираем 1 столбец
summary(df3)
View(df2)
View(df3)
# кластеры
km <- kmeans(df3, 3, nstart = 50) # по комнатам кластеризуем
# нарисуем цену и площадь
plot(log.df.price. ~ log.df.area.,
col=km$cluster+1, pch=km$cluster+16, # разделение по 4 переменным, поэтому в кооринатах для 2 нечеткое разделение.
data=df3)
points(km$centers[,1:2], pch=3, cex=2, lwd=3)
text(km$centers[,1], km$centers[,2], 1:3, cex=3, pos=4)
table(df2$df.rooms*10, km$cluster)
# install.packages("modeldata")
# Задача классификации и метод ближайших соседей
library(modeldata)
data("lending_club")
df <- lending_club
rm(lending_club)
summary(df)
str(df) # тип переменных
table(df$Class)
df$bad <- (df$Class == "bad") + 0
df$bad <- (df$Class == "bad") + 0
table(df$bad)
hist(df$funded_amnt) # гистограмма суммы, которую выдали
levels(df$term) # функция показывает уровни
df$term_num <- ifelse(df$term=="term_36", 36, 60) # срок, месяцы
table(df$term_num)
hist(df$int_rate) # ставка процента
table(df$sub_grade) # классы заемщиков
prop.table(table(df$sub_grade, df$Class))
table(df$sub_grade, df$Class)
#переведем в пропорции штуки
prop.table(table(df$sub_grade, df$Class), margin=1)
plot(prop.table(table(df$sub_grade, df$Class), margin=1))
#названия колонок в цифрах
df$grade=as.numeric(df$sub_grade)
plot(prop.table(table(df$grade, df$Class), margin=1))
#перевод дохода в лог с учетом минимума в 1000
df$log_inc=log(pmax(df$annual_inc, 1000))
#округлить ставки, перейти к пропорциям
plot(prop.table(table(round(df$int_rate), df$Class), margin=1))
#логит
lgt=glm(df$bad~df$funded_amnt+df$term_num+df$int_rate+df$grade+df$log_inc, family = "binomial")
summary(lgt)
lgt
fitted(lgt)#расчетные вероятности
predict.glm(lgt)
plot(df$bad~predict.glm(lgt),pch="|")
points(fitted(lgt)~predict.glm(lgt),pch="+", col="red")
#прогнозирование
#с использованием тренировочной выборки
n=nrow(df)
train=sample(n, 0.8*n)#80%
test=(1:n)[-train] #20%
#оцениваем туже модель, но с подмножеством
lgt1=glm(df$bad~df$funded_amnt+df$term_num+df$int_rate+df$grade+df$log_inc, family = binomial, subset = train)
pp=predict(lgt1, newdata=df[test, ], type="response") #df[test,] строчки трейн, столбцы все
hist(pp)
table(df$bad[test], pp>0.4)#матрица
table(df$bad[test], pp>0.4)#матрица
#оцениваем туже модель, но с подмножеством
lgt1=glm(df$bad~df$funded_amnt+df$term_num+df$int_rate+df$grade+df$log_inc, family = binomial, subset = train)
pp=predict(lgt1, newdata=df[test, ], type="response") #df[test,] строчки трейн, столбцы все
hist(pp)
table(df$bad[test], pp>0.4)#матрица
#кривая ROC
install.packages("pROC")
pROC::plot.roc(df$bad[test],pp)
pROC::roc(df$bad[test],pp)
pROC::plot.roc(df$bad[test],pp)
#кривая ROC
install.packages("pROC")
install.packages("pROC")
pROC::plot.roc(df$bad[test],pp)
hist(pp)
View(df)
View(df)
